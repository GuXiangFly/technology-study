server.port=8088

##langchain4j????
#langchain4j.open-ai.chat-model.api-key=demo
#langchain4j.open-ai.chat-model.model-name=gpt-4o
##???????
#langchain4j.open-ai.chat-model.log-requests=true
#langchain4j.open-ai.chat-model.log-responses=true
#????debug??
logging.level.root=debug


#ollama
langchain4j.ollama.chat-model.base-url=http://localhost:11434
langchain4j.ollama.chat-model.model-name=qwen3:4b
langchain4j.ollama.chat-model.log-requests=true
langchain4j.ollama.chat-model.log-responses=true



langchain4j.community.dashscope.chat-model.api-key=sk-6c2c10cbcf3d4bf59c47ce830d1ac160
langchain4j.community.dashscope.chat-model.model-name=qwen-max